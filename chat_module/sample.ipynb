{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'b', 'a'}\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"a\", \"b\"}\n",
    "str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'formatters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIChatModule\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      4\u001b[0m load_dotenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../.env\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/chat_bot/chat_module/chat.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchat_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_client, get_async_client, get_n_tokens, get_token_limit, make_batch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmessage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtruncate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OldConversationTruncationModule\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunction_call\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallableFunction\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/chat_bot/chat_module/truncate.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     12\u001b[0m LOG_CONFIG_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logging_config.ini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLOG_CONFIG_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOldConversationTruncationModule\u001b[39;00m(BaseConversationLengthAdjuster):\n",
      "File \u001b[0;32m~/miniforge3/envs/viida-beta/lib/python3.10/logging/config.py:72\u001b[0m, in \u001b[0;36mfileConfig\u001b[0;34m(fname, defaults, disable_existing_loggers, encoding)\u001b[0m\n\u001b[1;32m     69\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m     70\u001b[0m         cp\u001b[38;5;241m.\u001b[39mread(fname, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m---> 72\u001b[0m formatters \u001b[38;5;241m=\u001b[39m \u001b[43m_create_formatters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# critical section\u001b[39;00m\n\u001b[1;32m     75\u001b[0m logging\u001b[38;5;241m.\u001b[39m_acquireLock()\n",
      "File \u001b[0;32m~/miniforge3/envs/viida-beta/lib/python3.10/logging/config.py:105\u001b[0m, in \u001b[0;36m_create_formatters\u001b[0;34m(cp)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_formatters\u001b[39m(cp):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create and return formatters\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     flist \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformatters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flist):\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/miniforge3/envs/viida-beta/lib/python3.10/configparser.py:965\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_section \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_section(key):\n\u001b[0;32m--> 965\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'formatters'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from chat import OpenAIChatModule\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "\n",
    "chat = OpenAIChatModule(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    model_name=\"gpt-3.5-turbo-0613\",\n",
    ")\n",
    "\n",
    "message = \"こんにちは\"\n",
    "response = chat.run(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResults(message={'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}, usage=Usage(prompt_tokens=8, completion_tokens=14), prompt=[{'role': 'user', 'content': 'こんにちは'}])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: [{'role': 'user', 'content': 'やあ'}]\n",
      "こんにちは！何かお手伝いできますか？\n",
      "===\n",
      "\n",
      "message={'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'} usage=Usage(prompt_tokens=3, completion_tokens=15) prompt=[{'role': 'user', 'content': 'やあ'}]\n"
     ]
    }
   ],
   "source": [
    "# For streaming response\n",
    "\n",
    "message = \"やあ\"\n",
    "response = chat(message, stream=True)\n",
    "\n",
    "prev_response = \"\"\n",
    "for chunk in response:\n",
    "    if isinstance(chunk, str):\n",
    "        delta = chunk.replace(prev_response, \"\")\n",
    "        print(delta, end=\"\")\n",
    "        prev_response = chunk\n",
    "    else:\n",
    "        break\n",
    "print(\"\\n===\\n\")\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is printed before the response is generated!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response... for 猫の名前を決めてください\n",
      "Generating response... for 犬の名前を決めてください\n",
      "Response generated!\n",
      "message={'role': 'assistant', 'content': 'はい、どのような名前がお好みですか？性別や特徴など教えていただけると、より具体的な名前を提案できます。'} usage=Usage(prompt_tokens=19, completion_tokens=51) prompt=[{'role': 'user', 'content': '猫の名前を決めてください'}]\n",
      "Response generated!\n",
      "message={'role': 'assistant', 'content': 'もちろんです！以下にいくつかの犬の名前の提案をさせていただきます。\\n\\n1. チャーリー\\n2. マックス\\n3. ベイリー\\n4. ルーシー\\n5. ロッキー\\n6. レオ\\n7. ルナ\\n8. ココ\\n9. ボクサー\\n10. ダイアナ\\n\\nどれか気に入った名前はありますか？もしご希望の名前がなければ、もう少し情報を教えていただければ、より適切な名前を提案できるかもしれません。'} usage=Usage(prompt_tokens=19, completion_tokens=175) prompt=[{'role': 'user', 'content': '犬の名前を決めてください'}]\n"
     ]
    }
   ],
   "source": [
    "# For async response\n",
    "import asyncio\n",
    "\n",
    "async def call_gpt(message): \n",
    "    response = \"\"  \n",
    "    print(\"Generating response... for \" + message)\n",
    "    response = await chat.arun(message)\n",
    "    print(\"Response generated!\")\n",
    "    if response != \"\":\n",
    "        print(response)\n",
    "\n",
    "asyncio.create_task(call_gpt(\"猫の名前を決めてください\"))\n",
    "asyncio.create_task(call_gpt(\"犬の名前を決めてください\"))\n",
    "\n",
    "print(\"This is printed before the response is generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 0\n",
      "Message: {'role': 'user', 'content': 'やあ'}\n",
      "{'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}\n",
      "Total tokens: 0\n",
      "Message: {'role': 'user', 'content': '特にないよ'}\n",
      "Total tokens: 6\n",
      "Message: {'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}\n",
      "Total tokens: 21\n",
      "Message: {'role': 'user', 'content': 'やあ'}\n",
      "{'role': 'assistant', 'content': 'そうですか、もし何か質問や相談があれば遠慮なくお知らせください。お手伝いできることがあれば喜んでお応えします！'}\n",
      "Total tokens: 0\n",
      "Message: {'role': 'user', 'content': 'わかった'}\n",
      "Total tokens: 5\n",
      "Message: {'role': 'assistant', 'content': 'そうですか、もし何か質問や相談があれば遠慮なくお知らせください。お手伝いできることがあれば喜んでお応えします！'}\n",
      "Total tokens: 64\n",
      "Message: {'role': 'user', 'content': '特にないよ'}\n",
      "Total tokens: 70\n",
      "Message: {'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}\n",
      "Total tokens: 85\n",
      "Message: {'role': 'user', 'content': 'やあ'}\n",
      "{'role': 'assistant', 'content': '分かりました。もし何か困ったことや質問が生じたら、いつでもお知らせください。お手伝いできることがあれば喜んでお応えします。それでは、どうぞ良い一日をお過ごしください！'}\n",
      "Total tokens: 0\n",
      "Message: {'role': 'user', 'content': 'はーい'}\n",
      "Total tokens: 4\n",
      "Message: {'role': 'assistant', 'content': '分かりました。もし何か困ったことや質問が生じたら、いつでもお知らせください。お手伝いできることがあれば喜んでお応えします。それでは、どうぞ良い一日をお過ごしください！'}\n",
      "Total tokens: 84\n",
      "Message: {'role': 'user', 'content': 'わかった'}\n",
      "Total tokens: 89\n",
      "Message: {'role': 'assistant', 'content': 'そうですか、もし何か質問や相談があれば遠慮なくお知らせください。お手伝いできることがあれば喜んでお応えします！'}\n",
      "Total tokens: 148\n",
      "Message: {'role': 'user', 'content': '特にないよ'}\n",
      "Total tokens: 154\n",
      "Message: {'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}\n",
      "Total tokens: 169\n",
      "Message: {'role': 'user', 'content': 'やあ'}\n",
      "{'role': 'assistant', 'content': 'ありがとうございます！もし何かあればいつでもお知らせください。お役に立てることがあれば喜んでお手伝いします。良い一日をお過ごしください！'}\n",
      "Total tokens: 0\n",
      "Message: {'role': 'user', 'content': 'bye'}\n",
      "Total tokens: 2\n",
      "Message: {'role': 'assistant', 'content': 'ありがとうございます！もし何かあればいつでもお知らせください。お役に立てることがあれば喜んでお手伝いします。良い一日をお過ごしください！'}\n",
      "Total tokens: 60\n",
      "Message: {'role': 'user', 'content': 'はーい'}\n",
      "Total tokens: 64\n",
      "Message: {'role': 'assistant', 'content': '分かりました。もし何か困ったことや質問が生じたら、いつでもお知らせください。お手伝いできることがあれば喜んでお応えします。それでは、どうぞ良い一日をお過ごしください！'}\n",
      "Total tokens: 144\n",
      "Message: {'role': 'user', 'content': 'わかった'}\n",
      "Total tokens: 149\n",
      "Message: {'role': 'assistant', 'content': 'そうですか、もし何か質問や相談があれば遠慮なくお知らせください。お手伝いできることがあれば喜んでお応えします！'}\n",
      "Total tokens: 208\n",
      "Message: {'role': 'user', 'content': '特にないよ'}\n",
      "Total tokens: 214\n",
      "Message: {'role': 'assistant', 'content': 'こんにちは！何かお手伝いできますか？'}\n",
      "Total tokens: 229\n",
      "Message: {'role': 'user', 'content': 'やあ'}\n",
      "{'role': 'assistant', 'content': 'さようなら！お疲れ様でした。また何かあればお気軽にお声掛けください。良い一日をお過ごしください！'}\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"やあ\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"こんにちは！何かお手伝いできますか？\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"特にないよ\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"そうですか、もし何か質問や相談があれば遠慮なくお知らせください。お手伝いできることがあれば喜んでお応えします！\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"わかった\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"分かりました。もし何か困ったことや質問が生じたら、いつでもお知らせください。お手伝いできることがあれば喜んでお応えします。それでは、どうぞ良い一日をお過ごしください！\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"はーい\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"ありがとうございます！もし何かあればいつでもお知らせください。お役に立てることがあれば喜んでお手伝いします。良い一日をお過ごしください！\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"bye\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"さようなら！お疲れ様でした。また何かあればお気軽にお声掛けください。良い一日をお過ごしください！\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Conversation memory\n",
    "\n",
    "from memory import JSONConversationMemory\n",
    "\n",
    "chat = OpenAIChatModule(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    model_name=\"gpt-3.5-turbo-0613\",\n",
    "    conversation_memory=JSONConversationMemory(\"conversation.json\")\n",
    ")\n",
    "\n",
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    response = chat.run(message)\n",
    "    print(response.message)\n",
    "    \n",
    "    if message == \"bye\":\n",
    "        break\n",
    "\n",
    "with open(\"conversation.json\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: [{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate personal experiences.\"}, {'role': 'user', 'content': 'おはよう'}, {'role': 'assistant', 'content': 'おはようございます！朝ですね。今日はどんな一日になるか楽しみですね。何か特別な予定や目標はありますか？私はいつでもお手伝いできるので、何かお困りのことがあれば教えてください！'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'おはようございます！特別な予定や目標はありませんが、今日は仕事や勉強に集中して過ごしたいと思っています。何かアドバイスやモチベーションをくれる言葉はありますか？'}, {'role': 'user', 'content': ''}]\n",
      "messages: [{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate personal experiences.\"}, {'role': 'user', 'content': 'おはよう'}, {'role': 'assistant', 'content': 'おはようございます！朝ですね。今日はどんな一日になるか楽しみですね。何か特別な予定や目標はありますか？私はいつでもお手伝いできるので、何かお困りのことがあれば教えてください！'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'おはようございます！特別な予定や目標はありませんが、今日は仕事や勉強に集中して過ごしたいと思っています。何かアドバイスやモチベーションをくれる言葉はありますか？'}, {'role': 'user', 'content': ''}]\n",
      "Message: [{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate personal experiences.\"}, {'role': 'user', 'content': 'おはよう'}, {'role': 'assistant', 'content': 'おはようございます！朝ですね。今日はどんな一日になるか楽しみですね。何か特別な予定や目標はありますか？私はいつでもお手伝いできるので、何かお困りのことがあれば教えてください！'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'おはようございます！特別な予定や目標はありませんが、今日は仕事や勉強に集中して過ごしたいと思っています。何かアドバイスやモチベーションをくれる言葉はありますか？'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'もちろんです！頑張っているあなたに対して、いくつかの励ましの言葉をお伝えします。\\n\\n1. 「一歩ずつ進めば、必ず目標に近づけます。」大きな目標を達成するためには、小さな一歩から始めましょう。毎日少しずつ進めば、必ず成果が現れます。\\n\\n2. 「困難な時こそ、成長のチャンスです。」困難や挫折は避けられないものですが、それらを乗り越えることで自己成長が生まれます。自信を持って挑戦しましょう。\\n\\n3. 「自分自身を信じてください。」自分の能力や可能性を信じることは、成功への第一歩です。自分に自信を持ち、自分の力を信じて前に進んでください。\\n\\n4. 「努力は必ず報われます。」努力が報われないこともあるかもしれませんが、それは一時的なものです。継続的な努力は必ず結果を生み出します。諦めずに頑張りましょう。\\n\\n5. 「自分の成長を楽しんでください。」目標に向かって頑張ることは大切ですが、その過程を楽しむことも忘れずに。自分の成長や進歩を喜び、前向きな気持ちを持ち続けましょう。\\n\\nどんな困難や挑戦があっても、あなたはそれを乗り越える力を持っています。自分自身を信じて、一歩ずつ前進してください。応援しています！'}, {'role': 'user', 'content': ''}]\n",
      "Truncated message: {'role': 'assistant', 'content': 'しの言葉をお伝えします。\\n\\n1. 「一歩ずつ進めば、必ず目標に近づけます。」大きな目標を達成するためには、小さな一歩から始めましょう。毎日少しずつ進めば、必ず成果が現れます。\\n\\n2. 「困難な時こそ、成長のチャンスです。」困難や挫折は避けられないものですが、それらを乗り越えることで自己成長が生まれます。自信を持って挑戦しましょう。\\n\\n3. 「自分自身を信じてください。」自分の能力や可能性を信じることは、成功への第一歩です。自分に自信を持ち、自分の力を信じて前に進んでください。\\n\\n4. 「努力は必ず報われます。」努力が報われないこともあるかもしれませんが、それは一時的なものです。継続的な努力は必ず結果を生み出します。諦めずに頑張りましょう。\\n\\n5. 「自分の成長を楽しんでください。」目標に向かって頑張ることは大切ですが、その過程を楽しむことも忘れずに。自分の成長や進歩を喜び、前向きな気持ちを持ち続けましょう。\\n\\nどんな困難や挑戦があっても、あなたはそれを乗り越える力を持っています。自分自身を信じて、一歩ずつ前進してください。応援しています！'}\n",
      "messages: [{'role': 'assistant', 'content': 'しの言葉をお伝えします。\\n\\n1. 「一歩ずつ進めば、必ず目標に近づけます。」大きな目標を達成するためには、小さな一歩から始めましょう。毎日少しずつ進めば、必ず成果が現れます。\\n\\n2. 「困難な時こそ、成長のチャンスです。」困難や挫折は避けられないものですが、それらを乗り越えることで自己成長が生まれます。自信を持って挑戦しましょう。\\n\\n3. 「自分自身を信じてください。」自分の能力や可能性を信じることは、成功への第一歩です。自分に自信を持ち、自分の力を信じて前に進んでください。\\n\\n4. 「努力は必ず報われます。」努力が報われないこともあるかもしれませんが、それは一時的なものです。継続的な努力は必ず結果を生み出します。諦めずに頑張りましょう。\\n\\n5. 「自分の成長を楽しんでください。」目標に向かって頑張ることは大切ですが、その過程を楽しむことも忘れずに。自分の成長や進歩を喜び、前向きな気持ちを持ち続けましょう。\\n\\nどんな困難や挑戦があっても、あなたはそれを乗り越える力を持っています。自分自身を信じて、一歩ずつ前進してください。応援しています！'}, {'role': 'user', 'content': ''}]\n",
      "{'role': 'assistant', 'content': 'ありがとうございます。励ましの言葉を聞くと、心が温かくなります。自分自身を信じて、一歩ずつ進んでいきます。困難な時こそ成長のチャンスと捉え、努力を続けていきます。自分の成長を楽しむことも忘れずに、前向きな気持ちで頑張ります。改めて、ありがとうございました。'}\n"
     ]
    }
   ],
   "source": [
    "# Adjusting context length\n",
    "\n",
    "from memory import JSONConversationMemory\n",
    "from truncate import OldConversationTruncationModule\n",
    "\n",
    "chat = OpenAIChatModule(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    model_name=\"gpt-3.5-turbo-0613\",\n",
    "    conversation_memory=JSONConversationMemory(\"conversation.json\"),\n",
    "    conversation_length_adjuster=OldConversationTruncationModule(\n",
    "        model_name=\"gpt-3.5-turbo-0613\",\n",
    "        context_length=400\n",
    "    )\n",
    ")\n",
    "\n",
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    response = chat.run(message)\n",
    "    print(response.message)\n",
    "    \n",
    "    if message == \"bye\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viida-beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
